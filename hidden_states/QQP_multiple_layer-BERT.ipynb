{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2DoubleHeadsModel, AdamW, BertTokenizer, BertForSequenceClassification, BertModel, get_linear_schedule_with_warmup\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset, SequentialSampler)\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../data/glue_data/QQP/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(directory+\"train.tsv\", sep = \"\\t\",  quoting = 3)\n",
    "test = pd.read_csv(directory+\"test.tsv\", sep = \"\\t\",   quoting = 3)\n",
    "dev = pd.read_csv(directory+\"dev.tsv\", sep = \"\\t\",   quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "dev = dev.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"BERT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"BERT\":\n",
    "    train_sentences_a = train['question1'].values\n",
    "    train_sentences_b = train['question2'].values\n",
    "    train_labels = train['is_duplicate'].values\n",
    "    \n",
    "    test_sentences_a = dev['question1'].values\n",
    "    test_sentences_b = dev['question2'].values\n",
    "    test_labels = dev['is_duplicate'].values\n",
    "    \n",
    "elif model_name == \"gpt2\":\n",
    "    train_sentences_a = train['question1'].values\n",
    "    train_sentences_b = train['question2'].values\n",
    "    train_labels = train['is_duplicate'].values\n",
    "    \n",
    "    test_sentences_a = dev['question1'].values\n",
    "    test_sentences_b = dev['question2'].values\n",
    "    test_labels = dev['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 128\n",
    "if model_name == \"BERT\":\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "elif model_name == \"gpt2\":\n",
    "    special_tokens_dict = {'bos_token':'_start_','sep_token':'[SEP]', 'cls_token': '[CLS]'}\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2', do_lower_case=True)\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids = [tokenizer.encode(sent_a, text_pair=sent_b, add_special_tokens = True) for sent_a, sent_b in zip(train_sentences_a,train_sentences_b)]\n",
    "test_input_ids = [tokenizer.encode(sent_a, text_pair=sent_b, add_special_tokens = True) for sent_a, sent_b in zip(test_sentences_a,test_sentences_b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "train_input_ids = pad_sequences(train_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "test_input_ids = pad_sequences(test_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attention_masks = []\n",
    "test_attention_masks = []\n",
    "\n",
    "for seq in train_input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    train_attention_masks.append(seq_mask)\n",
    "    \n",
    "for seq in test_input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    test_attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_input_ids)\n",
    "train_masks = torch.tensor(train_attention_masks)\n",
    "train_labels = torch.tensor(train_labels).long()\n",
    "\n",
    "test_inputs = torch.tensor(test_input_ids)\n",
    "test_masks = torch.tensor(test_attention_masks)\n",
    "test_labels = torch.tensor(test_labels).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"BERT\":\n",
    "    model = BertForSequenceClassification.from_pretrained(\"/tmp/BERT/MRPC\", num_labels=2)\n",
    "    #model = torch.load('./COLA-finetuned-BERT-v2.pt')\n",
    "elif model_name == \"gpt2\":\n",
    "    #model = GPT2DoubleHeadsModel.from_pretrained(\"gpt2\", num_labels = 2)\n",
    "    model = torch.load('./MRPC-finetuned-GPT2.pt')\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "linears = [nn.Linear(768, 2).to(torch.device(\"cuda:0\")) for  x in range(0,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = [list(linears[i].named_parameters()) for i in range(0,13)]\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [[\n",
    "    {'params': [p for n, p in param_optimizer[i] if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer[i] if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "] for i in range(0,13)]\n",
    "\n",
    "optimizer = [AdamW(optimizer_grouped_parameters[i],\n",
    "                     lr=2e-5) for i in range(0,13)]\n",
    "\n",
    "scheduler = [get_linear_schedule_with_warmup(optimizer[i], num_warmup_steps=0, num_training_steps=len(train_dataloader)*3) for i in range (0,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name==\"BERT\":\n",
    "  model.bert.config.output_hidden_states = True\n",
    "  model.bert.config.is_decoder = False\n",
    "  model.bert.encoder.output_hidden_states = True\n",
    "  for i in range(0,len(model.bert.encoder.layer)): \n",
    "    model.bert.encoder.layer[i].is_decoder = False\n",
    "    model.bert.encoder.layer[i].output_hidden_states = True\n",
    "else:\n",
    "    model.transformer.output_hidden_states = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 3/3 [12:39:04<00:00, 15181.35s/it] \n"
     ]
    }
   ],
   "source": [
    "# Store our loss and accuracy for plotting\n",
    "train_loss_sets = [[] for i in range(0,13)]\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 3\n",
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "  \n",
    "  \n",
    "  # Training\n",
    "  \n",
    "  # Set our model to training mode (as opposed to evaluation mode)\n",
    "  for linear in linears:\n",
    "    linear.train()\n",
    "    \n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    #b_input_ids, b_masks, b_labels, b_cls_positions = batch\n",
    "    b_input_ids, b_masks, b_labels = batch\n",
    "    for i in range(0,13):\n",
    "      optimizer[i].zero_grad()\n",
    "    if(model_name==\"gpt2\"):\n",
    "        #model.transformer.output_hidden_states = True\n",
    "        outputs = model.transformer(b_input_ids, attention_mask=b_masks)\n",
    "        logits = []\n",
    "        for i in range(0,13):\n",
    "            hl = outputs[2][i] ## We taken the all hidden states and take the l layer\n",
    "            #h0 = outputs[3][0] ## Here we are using embeddings layer \n",
    "            #logits = linear(h0.view(-1,98304)) ## We flat the embeddings\n",
    "            logits.append(linears[i](hl[range(0,len(b_cls_positions)),b_cls_positions])) ## We take the classification token embedding to train the linear layer\n",
    "    else:\n",
    "        #h0 = model.bert.embeddings(b_input_ids)\n",
    "        #logits = linear(h0.view(-1,98304))\n",
    "        outputs = model.bert(b_input_ids, attention_mask=b_masks)\n",
    "        logits = []\n",
    "        for i in range(0,13):\n",
    "            hl = outputs[2][i] ## We taken the all hidden states and take the l layer\n",
    "            #h0 = outputs[3][0] ## Here we are using embeddings layer \n",
    "            #logits = linear(h0.view(-1,98304)) ## We flat the embeddings\n",
    "            logits.append(linears[i](hl[:,0])) ## We take the first token [CLS] embedding to train the linear layer\n",
    "\n",
    "    for i in range(0,13): \n",
    "      loss_fct = CrossEntropyLoss()\n",
    "      loss=loss_fct(logits[i].view(-1, logits[i].size(-1)),\n",
    "                              b_labels.view(-1))\n",
    "      \n",
    "      train_loss_sets[i].append(loss.item())\n",
    "      loss.backward(retain_graph=True)\n",
    "      optimizer[i].step()\n",
    "      # Update learning rate schedule\n",
    "      scheduler[i].step()\n",
    "    \n",
    "#if model == \"gpt2\":\n",
    "#  torch.save(linear, \"/content/drive/My Drive/linear_gpt2_layer1.pt\")\n",
    "#else:\n",
    "#  torch.save(linear,\"/content/drive/My Drive/linear_BERT.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [[] for i in range(0,13)]\n",
    "\n",
    "for linear in linears:\n",
    "    linear.eval()\n",
    "\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    #b_input_ids, b_masks, b_labels, b_cls_positions = batch\n",
    "    b_input_ids, b_masks, b_labels = batch\n",
    "    with torch.no_grad():\n",
    "        if(model_name==\"gpt2\"):\n",
    "            outputs = model.transformer(b_input_ids, attention_mask=b_masks)\n",
    "            logits = []\n",
    "            for i in range(0,13):\n",
    "                hl = outputs[2][i] ## We taken the all hidden states and take the l layer\n",
    "                #h0 = outputs[3][0] ## Here we are using embeddings layer \n",
    "                #logits = linear(h0.view(-1,98304)) ## We flat the embeddings\n",
    "                logits.append(linears[i](hl[range(0,len(b_cls_positions)),b_cls_positions])) ## We take the classification token embedding to t\n",
    "        else:\n",
    "            outputs = outputs = model.bert(b_input_ids, attention_mask=b_masks)\n",
    "            logits = []\n",
    "            for j in range(0,13):\n",
    "                hl = outputs[2][j] ## We taken the all hidden states and take the l layer\n",
    "                #h0 = outputs[3][0] ## Here we are using embeddings layer \n",
    "                #logits = linear(h0.view(-1,98304)) ## We flat the embeddings\n",
    "                logits.append(linears[j](hl[:,0])) ## We take the first token [CLS] embedding to train the linear layer\n",
    "    for j in range(0,13):\n",
    "        logits[j] = logits[j].detach().cpu().numpy()\n",
    "        preds[j].append(logits[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6318    1.0000    0.7744     25545\n",
      "           1     0.0000    0.0000    0.0000     14885\n",
      "\n",
      "    accuracy                         0.6318     40430\n",
      "   macro avg     0.3159    0.5000    0.3872     40430\n",
      "weighted avg     0.3992    0.6318    0.4893     40430\n",
      "\n",
      "Accuracy:  0.6318327974276527\n",
      "layer 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6652    0.9026    0.7660     25545\n",
      "           1     0.5688    0.2204    0.3177     14885\n",
      "\n",
      "    accuracy                         0.6515     40430\n",
      "   macro avg     0.6170    0.5615    0.5418     40430\n",
      "weighted avg     0.6297    0.6515    0.6009     40430\n",
      "\n",
      "Accuracy:  0.651471679445956\n",
      "layer 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6791    0.8927    0.7714     25545\n",
      "           1     0.5999    0.2760    0.3781     14885\n",
      "\n",
      "    accuracy                         0.6657     40430\n",
      "   macro avg     0.6395    0.5844    0.5748     40430\n",
      "weighted avg     0.6500    0.6657    0.6266     40430\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/transformers-v2.5.1/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6656937917388078\n",
      "layer 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6978    0.8763    0.7769     25545\n",
      "           1     0.6216    0.3489    0.4469     14885\n",
      "\n",
      "    accuracy                         0.6821     40430\n",
      "   macro avg     0.6597    0.6126    0.6119     40430\n",
      "weighted avg     0.6698    0.6821    0.6554     40430\n",
      "\n",
      "Accuracy:  0.6820925055651744\n",
      "layer 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7401    0.8418    0.7876     25545\n",
      "           1     0.6446    0.4926    0.5584     14885\n",
      "\n",
      "    accuracy                         0.7132     40430\n",
      "   macro avg     0.6923    0.6672    0.6730     40430\n",
      "weighted avg     0.7049    0.7132    0.7033     40430\n",
      "\n",
      "Accuracy:  0.7132080138511007\n",
      "layer 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7530    0.8315    0.7903     25545\n",
      "           1     0.6478    0.5319    0.5842     14885\n",
      "\n",
      "    accuracy                         0.7212     40430\n",
      "   macro avg     0.7004    0.6817    0.6872     40430\n",
      "weighted avg     0.7143    0.7212    0.7144     40430\n",
      "\n",
      "Accuracy:  0.7211971308434331\n",
      "layer 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7672    0.8354    0.7999     25545\n",
      "           1     0.6667    0.5651    0.6117     14885\n",
      "\n",
      "    accuracy                         0.7359     40430\n",
      "   macro avg     0.7170    0.7002    0.7058     40430\n",
      "weighted avg     0.7302    0.7359    0.7306     40430\n",
      "\n",
      "Accuracy:  0.7358891911946575\n",
      "layer 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7733    0.8353    0.8031     25545\n",
      "           1     0.6722    0.5798    0.6226     14885\n",
      "\n",
      "    accuracy                         0.7412     40430\n",
      "   macro avg     0.7228    0.7076    0.7129     40430\n",
      "weighted avg     0.7361    0.7412    0.7367     40430\n",
      "\n",
      "Accuracy:  0.7412317585951026\n",
      "layer 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7816    0.8264    0.8033     25545\n",
      "           1     0.6695    0.6036    0.6349     14885\n",
      "\n",
      "    accuracy                         0.7444     40430\n",
      "   macro avg     0.7255    0.7150    0.7191     40430\n",
      "weighted avg     0.7403    0.7444    0.7413     40430\n",
      "\n",
      "Accuracy:  0.7443729903536977\n",
      "layer 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7865    0.8220    0.8039     25545\n",
      "           1     0.6689    0.6171    0.6420     14885\n",
      "\n",
      "    accuracy                         0.7465     40430\n",
      "   macro avg     0.7277    0.7195    0.7229     40430\n",
      "weighted avg     0.7432    0.7465    0.7442     40430\n",
      "\n",
      "Accuracy:  0.7465495918872125\n",
      "layer 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7820    0.8289    0.8048     25545\n",
      "           1     0.6727    0.6036    0.6363     14885\n",
      "\n",
      "    accuracy                         0.7459     40430\n",
      "   macro avg     0.7274    0.7162    0.7205     40430\n",
      "weighted avg     0.7418    0.7459    0.7427     40430\n",
      "\n",
      "Accuracy:  0.7459312391788276\n",
      "layer 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7792    0.8260    0.8019     25545\n",
      "           1     0.6670    0.5983    0.6308     14885\n",
      "\n",
      "    accuracy                         0.7421     40430\n",
      "   macro avg     0.7231    0.7121    0.7163     40430\n",
      "weighted avg     0.7379    0.7421    0.7389     40430\n",
      "\n",
      "Accuracy:  0.7421469206035123\n",
      "layer 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7711    0.8253    0.7973     25545\n",
      "           1     0.6591    0.5794    0.6167     14885\n",
      "\n",
      "    accuracy                         0.7348     40430\n",
      "   macro avg     0.7151    0.7024    0.7070     40430\n",
      "weighted avg     0.7298    0.7348    0.7308     40430\n",
      "\n",
      "Accuracy:  0.7348008904279001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "for i in range(0,13):\n",
    "    print(\"layer \" + str(i))\n",
    "    predictions = []\n",
    "    for pred in preds[i]:\n",
    "        p = np.argmax(pred, axis = 1)\n",
    "        for label in p:\n",
    "            predictions.append(label)\n",
    "    print(classification_report(test_labels, predictions, digits = 4))\n",
    "    print(\"Accuracy: \", accuracy_score(test_labels, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bots",
   "language": "python",
   "name": "bots"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
