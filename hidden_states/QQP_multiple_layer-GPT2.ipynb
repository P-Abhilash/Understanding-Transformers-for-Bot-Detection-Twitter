{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "ajtqlXWPEA4P",
    "outputId": "80579569-5c70-41bf-dc5a-31c4bdefa671"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2DoubleHeadsModel, AdamW, BertTokenizer, BertForSequenceClassification, BertModel, get_linear_schedule_with_warmup\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset, SequentialSampler)\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Z1QaVxnEF2n"
   },
   "outputs": [],
   "source": [
    "directory = \"../data/glue_data/QQP/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wr2Tuk61EIWK"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(directory+\"train.tsv\", sep = \"\\t\",  quoting = 3)\n",
    "test = pd.read_csv(directory+\"test.tsv\", sep = \"\\t\",   quoting = 3)\n",
    "dev = pd.read_csv(directory+\"dev.tsv\", sep = \"\\t\",   quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GQrOn4a7EbLq"
   },
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "dev = dev.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQbcI30mEKaM"
   },
   "outputs": [],
   "source": [
    "model_name = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YiweFHq4EMhI"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X6FPAgeLEOfJ"
   },
   "outputs": [],
   "source": [
    "if model_name == \"BERT\":\n",
    "    train_sentences = train[3].values\n",
    "    #train_sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in train_sentences]\n",
    "    train_labels = train[1].values\n",
    "\n",
    "    test_sentences = dev[3].values\n",
    "    #test_sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in test_sentences]\n",
    "    test_labels = dev[1].values\n",
    "    \n",
    "elif model_name == \"gpt2\":\n",
    "    train_sentences_a = train['question1'].values\n",
    "    train_sentences_b = train['question2'].values\n",
    "    train_labels = train['is_duplicate'].values\n",
    "    \n",
    "    test_sentences_a = dev['question1'].values\n",
    "    test_sentences_b = dev['question2'].values\n",
    "    test_labels = dev['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "ea82a844c53743d4b28068ad6889382f",
      "37402f1d6c104dd49e5cce5960c55ce6",
      "538524ef4ea6412a99a8bb986fa33371",
      "429e4f37f764454d9c56eb04d592b185",
      "68346858ea4744d087be682c63a4fd88",
      "8d043ff01613448eaf1424b8134e7414",
      "bfd64d2e98664e7382bea84e8189ec6c",
      "4b3a503a338c4418804f5324c8094330",
      "bca4f39bca11460f8513e127c0d1f759",
      "d5d67cb9b528404f8bb346a56dd483f8",
      "797bd8f1882c4da9b609d6ee2c5fc59b",
      "628f9a0592a34f6596cfe3faad1e0992",
      "2925e7faeba3473790bc74483c7fd51b",
      "dd692f80b6bc4d49be4fc2279106e6ff",
      "557f9a23fb694b4593ca0b771e0b6ae6",
      "18a9ec9600f14f37896de8119945559b"
     ]
    },
    "colab_type": "code",
    "id": "cNu39ls3ERMU",
    "outputId": "86da5826-f859-4240-833f-b465ab3108a6"
   },
   "outputs": [],
   "source": [
    "max_length = 128\n",
    "if model_name == \"BERT\":\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "elif model_name == \"gpt2\":\n",
    "    special_tokens_dict = {'bos_token':'_start_','sep_token':'[SEP]', 'cls_token': '[CLS]'}\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2', do_lower_case=True)\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BzZUrJuFEhHH"
   },
   "outputs": [],
   "source": [
    "start = tokenizer.convert_tokens_to_ids(\"_start_\")\n",
    "classify = tokenizer.convert_tokens_to_ids(\"[CLS]\")\n",
    "sep = tokenizer.convert_tokens_to_ids(\"[SEP]\")\n",
    "\n",
    "train_sentences_a_tokens = [tokenizer.encode(sent_a) for sent_a in train_sentences_a]\n",
    "train_sentences_b_tokens = [tokenizer.encode(sent_b) for sent_b in train_sentences_b]\n",
    "\n",
    "test_sentences_a_tokens = [tokenizer.encode(sent_a) for sent_a in test_sentences_a]\n",
    "test_sentences_b_tokens = [tokenizer.encode(sent_b) for sent_b in test_sentences_b]\n",
    "\n",
    "train_input_ids = [[start] + sent_a[:max_length-3] + [sep] + sent_b[:(max_length-(3+len(sent_a[:max_length-3])))] + [classify] for sent_a,sent_b in zip(train_sentences_a_tokens,train_sentences_b_tokens)]\n",
    "test_input_ids = [[start] + sent_a[:max_length-3] + [sep] + sent_b[:(max_length-(3+len(sent_a[:max_length-3])))] + [classify] for sent_a,sent_b in zip(test_sentences_a_tokens,test_sentences_b_tokens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nw2tHD5-EjNO"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "train_input_ids = pad_sequences(train_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "test_input_ids = pad_sequences(test_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ScVO7WwFAtX"
   },
   "outputs": [],
   "source": [
    "cls_position_train = np.argmax(train_input_ids==classify,axis=1)\n",
    "cls_position_test = np.argmax(test_input_ids==classify,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQ1c2x4NFDN7"
   },
   "outputs": [],
   "source": [
    "train_attention_masks = []\n",
    "test_attention_masks = []\n",
    "\n",
    "for seq in train_input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    train_attention_masks.append(seq_mask)\n",
    "    \n",
    "for seq in test_input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    test_attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5yLmWbtKFF_4"
   },
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_input_ids)\n",
    "train_masks = torch.tensor(train_attention_masks)\n",
    "train_labels = torch.tensor(train_labels).long()\n",
    "train_cls_positions= torch.tensor(cls_position_train)\n",
    "\n",
    "test_inputs = torch.tensor(test_input_ids)\n",
    "test_masks = torch.tensor(test_attention_masks)\n",
    "test_labels = torch.tensor(test_labels).long()\n",
    "test_cls_positions=torch.tensor(cls_position_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7tje4DzZFSIN"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels, train_cls_positions)\n",
    "#train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels, test_cls_positions)\n",
    "#test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mj8tXlp2FVop"
   },
   "outputs": [],
   "source": [
    "if model_name == \"BERT\":\n",
    "    #model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "    model = torch.load('./COLA-finetuned-BERT-v2.pt')\n",
    "elif model_name == \"gpt2\":\n",
    "    #model = GPT2DoubleHeadsModel.from_pretrained(\"gpt2\", num_labels = 2)\n",
    "    model = torch.load('/tmp/GPT2/QQP/model.bin')\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_C6fEzQ2FdSX"
   },
   "outputs": [],
   "source": [
    "linears = [nn.Linear(768, 2).to(torch.device(\"cuda:0\")) for  x in range(0,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAJq6KgDFi13"
   },
   "outputs": [],
   "source": [
    "param_optimizer = [list(linears[i].named_parameters()) for i in range(0,13)]\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [[\n",
    "    {'params': [p for n, p in param_optimizer[i] if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer[i] if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "] for i in range(0,13)]\n",
    "\n",
    "optimizer = [AdamW(optimizer_grouped_parameters[i],\n",
    "                     lr=2e-5) for i in range(0,13)]\n",
    "\n",
    "scheduler = [get_linear_schedule_with_warmup(optimizer[i], num_warmup_steps=0, num_training_steps=len(train_dataloader)*3) for i in range (0,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4UkBdkwFmQA"
   },
   "outputs": [],
   "source": [
    "if model_name==\"BERT\":\n",
    "  model.bert.config.output_hidden_states = True\n",
    "  model.bert.config.is_decoder = False\n",
    "  model.bert.encoder.output_hidden_states = True\n",
    "  for i in range(0,len(model.bert.encoder.layer)): \n",
    "    model.bert.encoder.layer[i].is_decoder = False\n",
    "    model.bert.encoder.layer[i].output_hidden_states = True\n",
    "else:\n",
    "    model.transformer.output_hidden_states = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DyYo5m8GFzuu",
    "outputId": "dacc3c6a-f751-4dbc-f1cb-7c8bad436795"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 3/3 [13:07:32<00:00, 15750.97s/it] \n"
     ]
    }
   ],
   "source": [
    "# Store our loss and accuracy for plotting\n",
    "train_loss_sets = [[] for i in range(0,13)]\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 3\n",
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "  \n",
    "  \n",
    "  # Training\n",
    "  \n",
    "  # Set our model to training mode (as opposed to evaluation mode)\n",
    "  for linear in linears:\n",
    "    linear.train()\n",
    "    \n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_masks, b_labels, b_cls_positions = batch\n",
    "    #b_input_ids, b_masks, b_labels = batch\n",
    "    for i in range(0,13):\n",
    "      optimizer[i].zero_grad()\n",
    "    if(model_name==\"gpt2\"):\n",
    "        #model.transformer.output_hidden_states = True\n",
    "        outputs = model.transformer(b_input_ids, attention_mask=b_masks)\n",
    "        logits = []\n",
    "        for i in range(0,13):\n",
    "            hl = outputs[2][i] ## We taken the all hidden states and take the l layer\n",
    "            #h0 = outputs[3][0] ## Here we are using embeddings layer \n",
    "            #logits = linear(h0.view(-1,98304)) ## We flat the embeddings\n",
    "            logits.append(linears[i](hl[range(0,len(b_cls_positions)),b_cls_positions])) ## We take the classification token embedding to train the linear layer\n",
    "    else:\n",
    "        #h0 = model.bert.embeddings(b_input_ids)\n",
    "        #logits = linear(h0.view(-1,98304))\n",
    "        outputs = model.bert(b_input_ids, attention_mask=b_masks)\n",
    "        logits = []\n",
    "        for i in range(0,13):\n",
    "            hl = outputs[2][i] ## We taken the all hidden states and take the l layer\n",
    "            #h0 = outputs[3][0] ## Here we are using embeddings layer \n",
    "            #logits = linear(h0.view(-1,98304)) ## We flat the embeddings\n",
    "            logits.append(linears[i](hl[:,0])) ## We take the first token [CLS] embedding to train the linear layer\n",
    "\n",
    "    for i in range(0,13): \n",
    "      loss_fct = CrossEntropyLoss()\n",
    "      loss=loss_fct(logits[i].view(-1, logits[i].size(-1)),\n",
    "                              b_labels.view(-1))\n",
    "      \n",
    "      train_loss_sets[i].append(loss.item())\n",
    "      loss.backward(retain_graph=True)\n",
    "      optimizer[i].step()\n",
    "      # Update learning rate schedule\n",
    "      scheduler[i].step()\n",
    "    \n",
    "#if model == \"gpt2\":\n",
    "#  torch.save(linear, \"/content/drive/My Drive/linear_gpt2_layer1.pt\")\n",
    "#else:\n",
    "#  torch.save(linear,\"/content/drive/My Drive/linear_BERT.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [[] for i in range(0,13)]\n",
    "\n",
    "for linear in linears:\n",
    "    linear.eval()\n",
    "\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_masks, b_labels, b_cls_positions = batch\n",
    "    #b_input_ids, b_masks, b_labels = batch\n",
    "    with torch.no_grad():\n",
    "        if(model_name==\"gpt2\"):\n",
    "            outputs = model.transformer(b_input_ids, attention_mask=b_masks)\n",
    "            logits = []\n",
    "            for i in range(0,13):\n",
    "                hl = outputs[2][i] ## We taken the all hidden states and take the l layer\n",
    "                #h0 = outputs[3][0] ## Here we are using embeddings layer \n",
    "                #logits = linear(h0.view(-1,98304)) ## We flat the embeddings\n",
    "                logits.append(linears[i](hl[range(0,len(b_cls_positions)),b_cls_positions])) ## We take the classification token embedding to t\n",
    "        else:\n",
    "            outputs = outputs = model.bert(b_input_ids, attention_mask=b_masks)\n",
    "            logits = []\n",
    "            for j in range(0,13):\n",
    "                hl = outputs[2][j] ## We taken the all hidden states and take the l layer\n",
    "                #h0 = outputs[3][0] ## Here we are using embeddings layer \n",
    "                #logits = linear(h0.view(-1,98304)) ## We flat the embeddings\n",
    "                logits.append(linears[j](hl[:,0])) ## We take the first token [CLS] embedding to train the linear layer\n",
    "    for j in range(0,13):\n",
    "        logits[j] = logits[j].detach().cpu().numpy()\n",
    "        preds[j].append(logits[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6319    0.9922    0.7721     25545\n",
      "           1     0.3774    0.0081    0.0158     14885\n",
      "\n",
      "    accuracy                         0.6299     40430\n",
      "   macro avg     0.5046    0.5002    0.3939     40430\n",
      "weighted avg     0.5382    0.6299    0.4937     40430\n",
      "\n",
      "Accuracy:  0.6299035369774919\n",
      "layer 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7578    0.8503    0.8014     25545\n",
      "           1     0.6751    0.5336    0.5960     14885\n",
      "\n",
      "    accuracy                         0.7337     40430\n",
      "   macro avg     0.7164    0.6919    0.6987     40430\n",
      "weighted avg     0.7273    0.7337    0.7258     40430\n",
      "\n",
      "Accuracy:  0.7337125896611427\n",
      "layer 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7692    0.8460    0.8058     25545\n",
      "           1     0.6810    0.5644    0.6172     14885\n",
      "\n",
      "    accuracy                         0.7423     40430\n",
      "   macro avg     0.7251    0.7052    0.7115     40430\n",
      "weighted avg     0.7367    0.7423    0.7364     40430\n",
      "\n",
      "Accuracy:  0.7422953252535246\n",
      "layer 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7673    0.8363    0.8003     25545\n",
      "           1     0.6678    0.5649    0.6120     14885\n",
      "\n",
      "    accuracy                         0.7364     40430\n",
      "   macro avg     0.7176    0.7006    0.7062     40430\n",
      "weighted avg     0.7307    0.7364    0.7310     40430\n",
      "\n",
      "Accuracy:  0.73635913925303\n",
      "layer 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7651    0.8314    0.7969     25545\n",
      "           1     0.6601    0.5620    0.6071     14885\n",
      "\n",
      "    accuracy                         0.7322     40430\n",
      "   macro avg     0.7126    0.6967    0.7020     40430\n",
      "weighted avg     0.7265    0.7322    0.7270     40430\n",
      "\n",
      "Accuracy:  0.7322038090526837\n",
      "layer 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7648    0.8291    0.7957     25545\n",
      "           1     0.6573    0.5624    0.6062     14885\n",
      "\n",
      "    accuracy                         0.7309     40430\n",
      "   macro avg     0.7111    0.6958    0.7009     40430\n",
      "weighted avg     0.7252    0.7309    0.7259     40430\n",
      "\n",
      "Accuracy:  0.7309423695275785\n",
      "layer 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7659    0.8278    0.7956     25545\n",
      "           1     0.6569    0.5657    0.6079     14885\n",
      "\n",
      "    accuracy                         0.7313     40430\n",
      "   macro avg     0.7114    0.6968    0.7018     40430\n",
      "weighted avg     0.7257    0.7313    0.7265     40430\n",
      "\n",
      "Accuracy:  0.7313133811526095\n",
      "layer 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7639    0.8169    0.7895     25545\n",
      "           1     0.6433    0.5666    0.6025     14885\n",
      "\n",
      "    accuracy                         0.7248     40430\n",
      "   macro avg     0.7036    0.6918    0.6960     40430\n",
      "weighted avg     0.7195    0.7248    0.7207     40430\n",
      "\n",
      "Accuracy:  0.7247588424437299\n",
      "layer 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7622    0.8174    0.7888     25545\n",
      "           1     0.6421    0.5622    0.5995     14885\n",
      "\n",
      "    accuracy                         0.7235     40430\n",
      "   macro avg     0.7022    0.6898    0.6942     40430\n",
      "weighted avg     0.7180    0.7235    0.7191     40430\n",
      "\n",
      "Accuracy:  0.7234726688102894\n",
      "layer 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7619    0.8153    0.7877     25545\n",
      "           1     0.6397    0.5628    0.5988     14885\n",
      "\n",
      "    accuracy                         0.7224     40430\n",
      "   macro avg     0.7008    0.6891    0.6933     40430\n",
      "weighted avg     0.7170    0.7224    0.7182     40430\n",
      "\n",
      "Accuracy:  0.7223596339351966\n",
      "layer 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7613    0.7997    0.7801     25545\n",
      "           1     0.6237    0.5698    0.5955     14885\n",
      "\n",
      "    accuracy                         0.7151     40430\n",
      "   macro avg     0.6925    0.6847    0.6878     40430\n",
      "weighted avg     0.7107    0.7151    0.7121     40430\n",
      "\n",
      "Accuracy:  0.7150630719762553\n",
      "layer 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7586    0.7999    0.7787     25545\n",
      "           1     0.6212    0.5631    0.5907     14885\n",
      "\n",
      "    accuracy                         0.7127     40430\n",
      "   macro avg     0.6899    0.6815    0.6847     40430\n",
      "weighted avg     0.7080    0.7127    0.7095     40430\n",
      "\n",
      "Accuracy:  0.7127133316843928\n",
      "layer 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7578    0.8610    0.8061     25545\n",
      "           1     0.6887    0.5276    0.5975     14885\n",
      "\n",
      "    accuracy                         0.7383     40430\n",
      "   macro avg     0.7232    0.6943    0.7018     40430\n",
      "weighted avg     0.7323    0.7383    0.7293     40430\n",
      "\n",
      "Accuracy:  0.7382883997031907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "for i in range(0,13):\n",
    "    print(\"layer \" + str(i))\n",
    "    predictions = []\n",
    "    for pred in preds[i]:\n",
    "        p = np.argmax(pred, axis = 1)\n",
    "        for label in p:\n",
    "            predictions.append(label)\n",
    "    print(classification_report(test_labels, predictions, digits = 4))\n",
    "    print(\"Accuracy: \", accuracy_score(test_labels, predictions))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GPT2-QQP-MultipleLayer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:transformers-v2.5.1]",
   "language": "python",
   "name": "conda-env-transformers-v2.5.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "18a9ec9600f14f37896de8119945559b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2925e7faeba3473790bc74483c7fd51b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "37402f1d6c104dd49e5cce5960c55ce6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "429e4f37f764454d9c56eb04d592b185": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b3a503a338c4418804f5324c8094330",
      "placeholder": "​",
      "style": "IPY_MODEL_bfd64d2e98664e7382bea84e8189ec6c",
      "value": "100% 1.04M/1.04M [00:01&lt;00:00, 960kB/s]"
     }
    },
    "4b3a503a338c4418804f5324c8094330": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "538524ef4ea6412a99a8bb986fa33371": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d043ff01613448eaf1424b8134e7414",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68346858ea4744d087be682c63a4fd88",
      "value": 1042301
     }
    },
    "557f9a23fb694b4593ca0b771e0b6ae6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "628f9a0592a34f6596cfe3faad1e0992": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18a9ec9600f14f37896de8119945559b",
      "placeholder": "​",
      "style": "IPY_MODEL_557f9a23fb694b4593ca0b771e0b6ae6",
      "value": "100% 456k/456k [00:00&lt;00:00, 504kB/s]"
     }
    },
    "68346858ea4744d087be682c63a4fd88": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "797bd8f1882c4da9b609d6ee2c5fc59b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd692f80b6bc4d49be4fc2279106e6ff",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2925e7faeba3473790bc74483c7fd51b",
      "value": 456318
     }
    },
    "8d043ff01613448eaf1424b8134e7414": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bca4f39bca11460f8513e127c0d1f759": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_797bd8f1882c4da9b609d6ee2c5fc59b",
       "IPY_MODEL_628f9a0592a34f6596cfe3faad1e0992"
      ],
      "layout": "IPY_MODEL_d5d67cb9b528404f8bb346a56dd483f8"
     }
    },
    "bfd64d2e98664e7382bea84e8189ec6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5d67cb9b528404f8bb346a56dd483f8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd692f80b6bc4d49be4fc2279106e6ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea82a844c53743d4b28068ad6889382f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_538524ef4ea6412a99a8bb986fa33371",
       "IPY_MODEL_429e4f37f764454d9c56eb04d592b185"
      ],
      "layout": "IPY_MODEL_37402f1d6c104dd49e5cce5960c55ce6"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
