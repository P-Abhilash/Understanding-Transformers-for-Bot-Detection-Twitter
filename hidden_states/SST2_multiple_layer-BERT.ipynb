{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup, GPT2Tokenizer, GPT2DoubleHeadsModel\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset, SequentialSampler)\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../data/SST2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(directory+\"train.tsv\", sep = \"\\t\")\n",
    "#test = pd.read_csv(directory+\"test.tsv\", sep = \"\\t\")\n",
    "dev = pd.read_csv(directory+\"dev.tsv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"BERT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"BERT\":\n",
    "    train_sentences = train['sentence'].values\n",
    "    train_sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in train_sentences]\n",
    "    train_labels = train['label'].values\n",
    "\n",
    "    test_sentences = dev['sentence'].values\n",
    "    test_sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in test_sentences]\n",
    "    test_labels = dev['label'].values\n",
    "    \n",
    "elif model_name == \"gpt2\":\n",
    "    train_sentences = train['sentence'].values\n",
    "    #train_sentences = [\"_start_ \" + sentence + \" _classify_\" for sentence in train_sentences]\n",
    "    train_labels = train['label'].values\n",
    "    \n",
    "    test_sentences = dev['sentence'].values\n",
    "    #test_sentences = [\"_start_ \" + sentence + \" _classify_\" for sentence in test_sentences]\n",
    "    test_labels = dev['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 128\n",
    "if model_name == \"BERT\":\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "elif model_name == \"gpt2\":\n",
    "    special_tokens = [\"_start_\", \"_classify_\"]\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2', do_lower_case=True)\n",
    "    tokenizer.add_tokens(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids = [tokenizer.encode(sent, add_special_tokens = False) for sent in train_sentences]\n",
    "test_input_ids = [tokenizer.encode(sent, add_special_tokens = False) for sent in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = tokenizer.convert_tokens_to_ids(\"_start_\")\n",
    "classify = tokenizer.convert_tokens_to_ids(\"_classify_\")\n",
    "train_input_ids = [[start] + tokenizer.encode(sent)[:(max_length-2)] + [classify] for sent in train_sentences]\n",
    "test_input_ids = [[start] + tokenizer.encode(sent)[:(max_length-2)] + [classify] for sent in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "train_input_ids = pad_sequences(train_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "test_input_ids = pad_sequences(test_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attention_masks = []\n",
    "test_attention_masks = []\n",
    "\n",
    "for seq in train_input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    train_attention_masks.append(seq_mask)\n",
    "    \n",
    "for seq in test_input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    test_attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_position_train = np.argmax(train_input_ids==classify,axis=1)\n",
    "cls_position_test = np.argmax(test_input_ids==classify,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_input_ids)\n",
    "train_masks = torch.tensor(train_attention_masks)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "#train_cls_positions= torch.tensor(cls_position_train)\n",
    "\n",
    "test_inputs = torch.tensor(test_input_ids)\n",
    "test_masks = torch.tensor(test_attention_masks)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "#test_cls_positions=torch.tensor(cls_position_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "#train_data = TensorDataset(train_inputs, train_masks, train_labels, train_cls_positions)\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "#test_data = TensorDataset(test_inputs, test_masks, test_labels, test_cls_positions)\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"BERT\":\n",
    "    #model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "    model = torch.load('../models/SST2-finetuned-BERT-v2.pt')\n",
    "elif model_name == \"gpt2\":\n",
    "    #model = GPT2DoubleHeadsModel.from_pretrained(\"gpt2\", num_labels = 2)\n",
    "    model = torch.load('../models/SST2-finetuned-GPT2.pt')\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "linears = [nn.Linear(768, 2).to(torch.device(\"cuda:0\")) for  x in range(0,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = [list(linears[i].named_parameters()) for i in range(0,13)]\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [[\n",
    "    {'params': [p for n, p in param_optimizer[i] if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer[i] if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "] for i in range(0,13)]\n",
    "\n",
    "optimizer = [AdamW(optimizer_grouped_parameters[i],\n",
    "                     lr=2e-5,) for i in range(0,13)]\n",
    "scheduler = [get_linear_schedule_with_warmup(optimizer[i], num_warmup_steps=0, num_training_steps=len(train_dataloader)*3) for i in range(0,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name==\"BERT\":\n",
    "  model.bert.config.output_hidden_states = True\n",
    "  model.bert.config.is_decoder = False\n",
    "  model.bert.encoder.output_hidden_states = True\n",
    "  for i in range(0,len(model.bert.encoder.layer)): \n",
    "    model.bert.encoder.layer[i].is_decoder = False\n",
    "    model.bert.encoder.layer[i].output_hidden_states = True\n",
    "else:\n",
    "    model.transformer.output_hidden_states = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 3/3 [2:45:34<00:00, 3311.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# Store our loss and accuracy for plotting\n",
    "train_loss_sets = [[] for i in range(0,13)]\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 3\n",
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "  \n",
    "  \n",
    "  # Training\n",
    "  \n",
    "  # Set our model to training mode (as opposed to evaluation mode)\n",
    "  for linear in linears:\n",
    "    linear.train()\n",
    "    \n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    #b_input_ids, b_masks, b_labels, b_cls_positions = batch\n",
    "    b_input_ids, b_masks, b_labels = batch\n",
    "    for i in range(0,13):\n",
    "      optimizer[i].zero_grad()\n",
    "    if(model_name==\"gpt2\"):\n",
    "        #model.transformer.output_hidden_states = True\n",
    "        outputs = model.transformer(b_input_ids, attention_mask=b_masks)\n",
    "        logits = []\n",
    "        for i in range(0,13):\n",
    "            hl = outputs[2][i] ## We taken the all hidden states and take the l layer\n",
    "            #h0 = outputs[3][0] ## Here we are using embeddings layer \n",
    "            #logits = linear(h0.view(-1,98304)) ## We flat the embeddings\n",
    "            logits.append(linears[i](hl[range(0,len(b_cls_positions)),b_cls_positions])) ## We take the classification token embedding to train the linear layer\n",
    "    else:\n",
    "        #h0 = model.bert.embeddings(b_input_ids)\n",
    "        #logits = linear(h0.view(-1,98304))\n",
    "        outputs = model.bert(b_input_ids, attention_mask=b_masks)\n",
    "        logits = []\n",
    "        for i in range(0,13):\n",
    "            hl = outputs[2][i] ## We taken the all hidden states and take the l layer\n",
    "            #h0 = outputs[3][0] ## Here we are using embeddings layer \n",
    "            #logits = linear(h0.view(-1,98304)) ## We flat the embeddings\n",
    "            logits.append(linears[i](hl[:,0])) ## We take the first token [CLS] embedding to train the linear layer\n",
    "\n",
    "    for i in range(0,13): \n",
    "      loss_fct = CrossEntropyLoss()\n",
    "      loss=loss_fct(logits[i].view(-1, logits[i].size(-1)),\n",
    "                              b_labels.view(-1))\n",
    "      \n",
    "      train_loss_sets[i].append(loss.item())\n",
    "      loss.backward(retain_graph=True)\n",
    "      optimizer[i].step()\n",
    "      # Update learning rate schedule\n",
    "      scheduler[i].step()\n",
    "    \n",
    "#if model == \"gpt2\":\n",
    "#  torch.save(linear, \"/content/drive/My Drive/linear_gpt2_layer1.pt\")\n",
    "#else:\n",
    "#  torch.save(linear,\"/content/drive/My Drive/linear_BERT.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [[] for i in range(0,13)]\n",
    "\n",
    "for linear in linears:\n",
    "    linear.eval()\n",
    "\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    #b_input_ids, b_masks, b_labels, b_cls_positions = batch\n",
    "    b_input_ids, b_masks, b_labels = batch\n",
    "    with torch.no_grad():\n",
    "        if(model_name==\"gpt2\"):\n",
    "            outputs = model.transformer(b_input_ids, attention_mask=b_masks)\n",
    "            logits = []\n",
    "            for i in range(0,13):\n",
    "                hl = outputs[2][i] ## We taken the all hidden states and take the l layer\n",
    "                #h0 = outputs[3][0] ## Here we are using embeddings layer \n",
    "                #logits = linear(h0.view(-1,98304)) ## We flat the embeddings\n",
    "                logits.append(linears[i](hl[range(0,len(b_cls_positions)),b_cls_positions])) ## We take the classification token embedding to t\n",
    "        else:\n",
    "            outputs = outputs = model.bert(b_input_ids, attention_mask=b_masks)\n",
    "            logits = []\n",
    "            for j in range(0,13):\n",
    "                hl = outputs[2][j] ## We taken the all hidden states and take the l layer\n",
    "                #h0 = outputs[3][0] ## Here we are using embeddings layer \n",
    "                #logits = linear(h0.view(-1,98304)) ## We flat the embeddings\n",
    "                logits.append(linears[j](hl[:,0])) ## We take the first token [CLS] embedding to train the linear layer\n",
    "    for j in range(0,13):\n",
    "        logits[j] = logits[j].detach().cpu().numpy()\n",
    "        preds[j].append(logits[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       428\n",
      "           1     0.5092    1.0000    0.6748       444\n",
      "\n",
      "    accuracy                         0.5092       872\n",
      "   macro avg     0.2546    0.5000    0.3374       872\n",
      "weighted avg     0.2593    0.5092    0.3436       872\n",
      "\n",
      "Accuracy:  0.5091743119266054\n",
      "layer 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.0140    0.0275       428\n",
      "           1     0.5110    0.9932    0.6748       444\n",
      "\n",
      "    accuracy                         0.5126       872\n",
      "   macro avg     0.5888    0.5036    0.3511       872\n",
      "weighted avg     0.5874    0.5126    0.3571       872\n",
      "\n",
      "Accuracy:  0.5126146788990825\n",
      "layer 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7019    0.5888    0.6404       428\n",
      "           1     0.6569    0.7590    0.7043       444\n",
      "\n",
      "    accuracy                         0.6755       872\n",
      "   macro avg     0.6794    0.6739    0.6723       872\n",
      "weighted avg     0.6790    0.6755    0.6729       872\n",
      "\n",
      "Accuracy:  0.6754587155963303\n",
      "layer 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7304    0.5888    0.6520       428\n",
      "           1     0.6660    0.7905    0.7230       444\n",
      "\n",
      "    accuracy                         0.6915       872\n",
      "   macro avg     0.6982    0.6897    0.6875       872\n",
      "weighted avg     0.6976    0.6915    0.6881       872\n",
      "\n",
      "Accuracy:  0.6915137614678899\n",
      "layer 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7678    0.6799    0.7212       428\n",
      "           1     0.7221    0.8018    0.7599       444\n",
      "\n",
      "    accuracy                         0.7420       872\n",
      "   macro avg     0.7450    0.7409    0.7405       872\n",
      "weighted avg     0.7445    0.7420    0.7409       872\n",
      "\n",
      "Accuracy:  0.7419724770642202\n",
      "layer 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7835    0.7103    0.7451       428\n",
      "           1     0.7438    0.8108    0.7759       444\n",
      "\n",
      "    accuracy                         0.7615       872\n",
      "   macro avg     0.7637    0.7605    0.7605       872\n",
      "weighted avg     0.7633    0.7615    0.7608       872\n",
      "\n",
      "Accuracy:  0.7614678899082569\n",
      "layer 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7942    0.7033    0.7460       428\n",
      "           1     0.7424    0.8243    0.7812       444\n",
      "\n",
      "    accuracy                         0.7649       872\n",
      "   macro avg     0.7683    0.7638    0.7636       872\n",
      "weighted avg     0.7678    0.7649    0.7639       872\n",
      "\n",
      "Accuracy:  0.7649082568807339\n",
      "layer 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8368    0.8505    0.8436       428\n",
      "           1     0.8535    0.8401    0.8468       444\n",
      "\n",
      "    accuracy                         0.8452       872\n",
      "   macro avg     0.8452    0.8453    0.8452       872\n",
      "weighted avg     0.8453    0.8452    0.8452       872\n",
      "\n",
      "Accuracy:  0.8451834862385321\n",
      "layer 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8451    0.8411    0.8431       428\n",
      "           1     0.8475    0.8514    0.8494       444\n",
      "\n",
      "    accuracy                         0.8463       872\n",
      "   macro avg     0.8463    0.8462    0.8463       872\n",
      "weighted avg     0.8463    0.8463    0.8463       872\n",
      "\n",
      "Accuracy:  0.8463302752293578\n",
      "layer 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8925    0.8925    0.8925       428\n",
      "           1     0.8964    0.8964    0.8964       444\n",
      "\n",
      "    accuracy                         0.8945       872\n",
      "   macro avg     0.8945    0.8945    0.8945       872\n",
      "weighted avg     0.8945    0.8945    0.8945       872\n",
      "\n",
      "Accuracy:  0.8944954128440367\n",
      "layer 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9155    0.9112    0.9133       428\n",
      "           1     0.9148    0.9189    0.9169       444\n",
      "\n",
      "    accuracy                         0.9151       872\n",
      "   macro avg     0.9151    0.9151    0.9151       872\n",
      "weighted avg     0.9151    0.9151    0.9151       872\n",
      "\n",
      "Accuracy:  0.9151376146788991\n",
      "layer 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9222    0.9136    0.9178       428\n",
      "           1     0.9174    0.9257    0.9215       444\n",
      "\n",
      "    accuracy                         0.9197       872\n",
      "   macro avg     0.9198    0.9196    0.9197       872\n",
      "weighted avg     0.9197    0.9197    0.9197       872\n",
      "\n",
      "Accuracy:  0.9197247706422018\n",
      "layer 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9220    0.9112    0.9166       428\n",
      "           1     0.9154    0.9257    0.9205       444\n",
      "\n",
      "    accuracy                         0.9186       872\n",
      "   macro avg     0.9187    0.9184    0.9185       872\n",
      "weighted avg     0.9186    0.9186    0.9186       872\n",
      "\n",
      "Accuracy:  0.9185779816513762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "for i in range(0,13):\n",
    "    print(\"layer \" + str(i))\n",
    "    predictions = []\n",
    "    for pred in preds[i]:\n",
    "        p = np.argmax(pred, axis = 1)\n",
    "        for label in p:\n",
    "            predictions.append(label)\n",
    "    print(classification_report(test_labels, predictions, digits = 4))\n",
    "    print(\"Accuracy: \", accuracy_score(test_labels, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
